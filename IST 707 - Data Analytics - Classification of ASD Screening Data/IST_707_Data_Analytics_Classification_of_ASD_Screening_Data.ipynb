{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST 707 - Data Analytics - Classification of ASD Screening Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/0mtANN9PqIv01soR+msF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frnunez/MS-Portfolio-Syracuse-University/blob/master/IST%20707%20-%20Data%20Analytics%20-%20Classification%20of%20ASD%20Screening%20Data/IST_707_Data_Analytics_Classification_of_ASD_Screening_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJkQS3GKQ9qY",
        "colab_type": "text"
      },
      "source": [
        "# Name: Francisco Nunez-Fondeur\n",
        "# Description: IST 707 - Syracuse University\n",
        "# Date: 05/16/2019 - Final Project - Autism AQ-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDHsTUdCvamu",
        "colab_type": "text"
      },
      "source": [
        "# CLASSIFICATION OF AUTISTIC SPECTRUM DISORDER SCREENING DATA\n",
        "<br>\n",
        "Autism Spectrum Disorder refers to a range of conditions characterized by challenges with social skills, repetitive behaviors, speech and non-verbal communication According to the Centers for Disease Control, autism affects an estimated 1 in 59 children in the United States. In 2013 the American Psychiatric Association merged four distinct diagnoses into one under the name of Autism Spectrum Disorder, there were previously referred to as autistic disorder, childhood disintegrate disorder, pervasive development disorder-not otherwise specified (PDD-NOS) and Asperger syndrome.\n",
        "For a long time, ASD was associated with a lengthy process to get properly diagnosed. With an increase in the number of ASD cases around the world, a faster screening tool was created called the Autism Spectrum Quotient (AQ) consisting of 50 questions. A condensed version the AQ-10 was created as a faster self-diagnosis tool to determine an individual’s position on the autism-normality spectrum. While the AQ-10 is NOT used for a definitive diagnosis, a score greater that 6/10 would be a flag that you should seek a professional diagnosis.\n",
        "<br>\n",
        "<br>\n",
        "<u>Objective</u>\n",
        "<br>\n",
        "While the tool is a great first step, there aren’t many available datasets associated with clinical screenings and behavior. Per Fadi Fayez Thabtah, creator of the set, most available datasets on autism are genetic in nature. The set consists of the responses to behavior questions on the AQ-10 tool along with the results. In addition, 10 individual characteristics were made part of this set which have been used by the behavioral sciences experts for ASD detection. I intend to also use classification to determine the effectiveness of not just the AQ-10 tool but also the individual traits provided in diagnosing ASD by using classification and clustering algorithms. I will be using decision trees, Naïve Bayes, k-NN and Support Vector Machines.\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UvDkXSPwHkJ",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries & Data\n",
        "Lets import the R packages we will be using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11zPLISEMdqk",
        "colab_type": "code",
        "outputId": "c0443900-c5f9-4151-a0ba-37214ef37816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#----- Installs ----#\n",
        "\n",
        "#Install c50\n",
        "if (!require(C50)) install.packages('C50')\n",
        "\n",
        "#Install caret\n",
        "if (!require(caret)) install.packages('caret')\n",
        "\n",
        "#countrycode\n",
        "if (!require(countrycode)) install.packages('countrycode')\n",
        "\n",
        "#Install class\n",
        "if (!require(class)) install.packages('class')  \n",
        "\n",
        "#Install dplyr\n",
        "if (!require(dplyr)) install.packages('dplyr')\n",
        "\n",
        "#Install e1071\n",
        "if (!require(e1071)) install.packages('e1071')\n",
        "\n",
        "#farff\n",
        "if (!require(farff)) install.packages('farff')\n",
        "\n",
        "#gmodels\n",
        "if (!require(gmodels)) install.packages('gmodels')\n",
        "\n",
        "#Install kernlab\n",
        "if (!require(kernlab)) install.packages('kernlab')\n",
        "\n",
        "#Install RWeka\n",
        "if (!require(RWeka)) install.packages('RWeka')\n",
        "\n",
        "#SQLDF\n",
        "if (!require(sqldf)) install.packages('sqldf')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: C50\n",
            "\n",
            "Loading required package: caret\n",
            "\n",
            "Loading required package: lattice\n",
            "\n",
            "Loading required package: ggplot2\n",
            "\n",
            "Loading required package: countrycode\n",
            "\n",
            "Loading required package: class\n",
            "\n",
            "Loading required package: dplyr\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "Loading required package: e1071\n",
            "\n",
            "Loading required package: farff\n",
            "\n",
            "Loading required package: gmodels\n",
            "\n",
            "Loading required package: kernlab\n",
            "\n",
            "\n",
            "Attaching package: ‘kernlab’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:ggplot2’:\n",
            "\n",
            "    alpha\n",
            "\n",
            "\n",
            "Loading required package: RWeka\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘RWeka’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘RWekajars’, ‘rJava’\n",
            "\n",
            "\n",
            "Warning message in install.packages(\"RWeka\"):\n",
            "“installation of package ‘rJava’ had non-zero exit status”\n",
            "Warning message in install.packages(\"RWeka\"):\n",
            "“installation of package ‘RWekajars’ had non-zero exit status”\n",
            "Warning message in install.packages(\"RWeka\"):\n",
            "“installation of package ‘RWeka’ had non-zero exit status”\n",
            "Loading required package: sqldf\n",
            "\n",
            "Loading required package: gsubfn\n",
            "\n",
            "Loading required package: proto\n",
            "\n",
            "Warning message:\n",
            "“no DISPLAY variable so Tk is not available”\n",
            "Loading required package: RSQLite\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiMxOnvMweJS",
        "colab_type": "text"
      },
      "source": [
        "Next I downloaded and imported the data. The data consists of three separate data sets available from the UCI Machine Learning Repository. The sets are divided by age; children (4-11), adolescents, (12-17) and adult (18 and over). The number of observations for each of the sets were 292 (children), 104 (adolescents), and 704 (adults) combining for 1100 total observations.  The attributes were: ASD Diagnosis (our classifier), age (in years), gender, ethnicity, born with jaundice (Y/N), Family member with ASD (Y/N), Relation of the person completing the test, Country of Residence, Use of a screening application previously, age description, Questions 1-10 of the AQ tool (each separate), and the Screening Score on the AQ-10. The set was distributed as an arff file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXHmu8ko0g0k",
        "colab_type": "code",
        "outputId": "fa26bc3a-532f-4a56-c51f-84c22b3917d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "# Child Set\n",
        "# Set url link for the location of the dataset\n",
        "      childURL <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00419/Autism-Screening-Child-Data%20Plus%20Description.zip\"\n",
        "      \n",
        "      # Download the .zip file and unzip contents\n",
        "      download.file(childURL, dest = \"child.zip\", mode = \"wb\") \n",
        "      unzip(\"child.zip\", exdir = \"child\")\n",
        "      \n",
        "      # Assess the files contained in the .zip file and then import each dataset\n",
        "      list.files(\"child\")\n",
        "      Autism_Child_Data <- readARFF(\"child/Autism-Child-Data.arff\")\n",
        "      #Autism_Child_Data <- readARFF(unz(\"child.zip\", \"Autism-Child-Data.arff\"))\n",
        "     # hubway_trips <- read.csv(unz(\"child.zip\", \"hubway_trips.csv\"))\n",
        "      \n",
        "      #Basic Descriptive Info\n",
        "      Autism_Child_Data[1:5, 1:10]\n",
        "      str(Autism_Child_Data)\n",
        "      dim(Autism_Child_Data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Autism-Child-Data.arff\"                      \n",
              "[2] \"Autism-Screening-Child-Data Description.docx\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'Autism-Child-Data.arff'\n\\item 'Autism-Screening-Child-Data Description.docx'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'Autism-Child-Data.arff'\n2. 'Autism-Screening-Child-Data Description.docx'\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Autism-Child-Data.arff'</li><li>'Autism-Screening-Child-Data Description.docx'</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse with reader=readr : child/Autism-Child-Data.arff\n",
            "\n",
            "Loading required package: readr\n",
            "\n",
            "header: 0.030000; preproc: 0.000000; data: 0.033000; postproc: 0.003000; total: 0.066000\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n",
              "1 1        1        0        0        1        1        0        1       \n",
              "2 1        1        0        0        1        1        0        1       \n",
              "3 1        1        0        0        0        1        1        1       \n",
              "4 0        1        0        0        1        1        0        0       \n",
              "5 1        1        1        1        1        1        1        1       \n",
              "  A9_Score A10_Score\n",
              "1 0        0        \n",
              "2 0        0        \n",
              "3 0        0        \n",
              "4 0        1        \n",
              "5 1        1        "
            ],
            "text/latex": "A data.frame: 5 × 10\n\\begin{tabular}{r|llllllllll}\n  & A1\\_Score & A2\\_Score & A3\\_Score & A4\\_Score & A5\\_Score & A6\\_Score & A7\\_Score & A8\\_Score & A9\\_Score & A10\\_Score\\\\\n  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n\\hline\n\t1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0\\\\\n\t2 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0\\\\\n\t3 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0\\\\\n\t4 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1\\\\\n\t5 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 5 × 10\n\n| <!--/--> | A1_Score &lt;fct&gt; | A2_Score &lt;fct&gt; | A3_Score &lt;fct&gt; | A4_Score &lt;fct&gt; | A5_Score &lt;fct&gt; | A6_Score &lt;fct&gt; | A7_Score &lt;fct&gt; | A8_Score &lt;fct&gt; | A9_Score &lt;fct&gt; | A10_Score &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 1 | 1 | 0 | 0 | 1 | 1 | 0 | 1 | 0 | 0 |\n| 2 | 1 | 1 | 0 | 0 | 1 | 1 | 0 | 1 | 0 | 0 |\n| 3 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 |\n| 4 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 1 |\n| 5 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 5 × 10</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>A1_Score</th><th scope=col>A2_Score</th><th scope=col>A3_Score</th><th scope=col>A4_Score</th><th scope=col>A5_Score</th><th scope=col>A6_Score</th><th scope=col>A7_Score</th><th scope=col>A8_Score</th><th scope=col>A9_Score</th><th scope=col>A10_Score</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "'data.frame':\t292 obs. of  21 variables:\n",
            " $ A1_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 2 1 2 2 2 1 ...\n",
            " $ A2_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 1 1 2 2 1 ...\n",
            " $ A3_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 2 2 2 2 2 ...\n",
            " $ A4_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 2 2 2 2 ...\n",
            " $ A5_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 1 2 2 2 2 2 2 2 ...\n",
            " $ A6_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 1 ...\n",
            " $ A7_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 2 1 1 2 2 2 ...\n",
            " $ A8_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 2 2 2 2 1 2 ...\n",
            " $ A9_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 1 1 1 ...\n",
            " $ A10_Score      : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 2 2 2 1 1 1 ...\n",
            " $ age            : num  6 6 6 5 5 4 5 5 11 11 ...\n",
            " $ gender         : Factor w/ 2 levels \"m\",\"f\": 1 1 1 2 1 1 1 2 2 2 ...\n",
            " $ ethnicity      : Factor w/ 10 levels \"Others\",\"Middle Eastern \",..: 1 2 NA NA 1 NA 3 2 2 NA ...\n",
            " $ jundice        : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 2 2 1 1 1 1 1 ...\n",
            " $ austim         : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 2 1 1 1 2 ...\n",
            " $ contry_of_res  : Factor w/ 52 levels \"Jordan\",\"United States\",..: 1 1 1 1 2 3 4 5 5 6 ...\n",
            " $ used_app_before: Factor w/ 2 levels \"no\",\"yes\": 1 1 2 1 1 1 1 1 1 1 ...\n",
            " $ result         : num  5 5 5 4 10 5 7 8 7 5 ...\n",
            " $ age_desc       : Factor w/ 1 level \"4-11 years\": 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ relation       : Factor w/ 5 levels \"Parent\",\"Self\",..: 1 1 NA NA 1 NA 1 1 1 NA ...\n",
            " $ Class/ASD      : Factor w/ 2 levels \"NO\",\"YES\": 1 1 1 1 2 1 2 2 2 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 292  21"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 292\n\\item 21\n\\end{enumerate*}\n",
            "text/markdown": "1. 292\n2. 21\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>292</li><li>21</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMXLTam45j9L",
        "colab_type": "code",
        "outputId": "eb499b49-22f4-42cc-d4a3-378193066a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Adolescent Set\n",
        "# Set url link for the location of the dataset\n",
        "      AdolescentURL <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00420/Autism-Adolescent-Data%20Plus%20Description.zip\"\n",
        "      \n",
        "      # Download the .zip file and unzip contents\n",
        "      download.file(AdolescentURL, dest = \"Adolescent.zip\", mode = \"wb\") \n",
        "      unzip(\"Adolescent.zip\", exdir = \"Adolescent\")\n",
        "      \n",
        "      # Assess the files contained in the .zip file and then import each dataset\n",
        "      list.files(\"Adolescent\")\n",
        "      Autism_Adolescent_Data <- readARFF(\"Adolescent/Autism-Adolescent-Data.arff\")\n",
        "      \n",
        "      #Basic Descriptive Info\n",
        "      Autism_Adolescent_Data[1:5, 1:10]\n",
        "      str(Autism_Adolescent_Data)\n",
        "      dim(Autism_Adolescent_Data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Autism-Adolescent-Data.arff\"                      \n",
              "[2] \"Autism-Screening-Adolescent-Data Description.docx\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'Autism-Adolescent-Data.arff'\n\\item 'Autism-Screening-Adolescent-Data Description.docx'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'Autism-Adolescent-Data.arff'\n2. 'Autism-Screening-Adolescent-Data Description.docx'\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Autism-Adolescent-Data.arff'</li><li>'Autism-Screening-Adolescent-Data Description.docx'</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse with reader=readr : Adolescent/Autism-Adolescent-Data.arff\n",
            "\n",
            "header: 0.021000; preproc: 0.000000; data: 0.002000; postproc: 0.003000; total: 0.026000\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n",
              "1 0        0        0        1        1        1        1        1       \n",
              "2 0        0        0        0        0        0        0        0       \n",
              "3 0        0        0        0        0        0        0        0       \n",
              "4 0        1        1        1        1        1        0        1       \n",
              "5 1        1        1        1        1        1        1        0       \n",
              "  A9_Score A10_Score\n",
              "1 1        0        \n",
              "2 1        1        \n",
              "3 1        1        \n",
              "4 1        0        \n",
              "5 0        0        "
            ],
            "text/latex": "A data.frame: 5 × 10\n\\begin{tabular}{r|llllllllll}\n  & A1\\_Score & A2\\_Score & A3\\_Score & A4\\_Score & A5\\_Score & A6\\_Score & A7\\_Score & A8\\_Score & A9\\_Score & A10\\_Score\\\\\n  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n\\hline\n\t1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0\\\\\n\t2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1\\\\\n\t3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1\\\\\n\t4 & 0 & 1 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 0\\\\\n\t5 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 5 × 10\n\n| <!--/--> | A1_Score &lt;fct&gt; | A2_Score &lt;fct&gt; | A3_Score &lt;fct&gt; | A4_Score &lt;fct&gt; | A5_Score &lt;fct&gt; | A6_Score &lt;fct&gt; | A7_Score &lt;fct&gt; | A8_Score &lt;fct&gt; | A9_Score &lt;fct&gt; | A10_Score &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 0 |\n| 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |\n| 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |\n| 4 | 0 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 |\n| 5 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 5 × 10</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>A1_Score</th><th scope=col>A2_Score</th><th scope=col>A3_Score</th><th scope=col>A4_Score</th><th scope=col>A5_Score</th><th scope=col>A6_Score</th><th scope=col>A7_Score</th><th scope=col>A8_Score</th><th scope=col>A9_Score</th><th scope=col>A10_Score</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "'data.frame':\t104 obs. of  21 variables:\n",
            " $ A1_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 2 1 2 2 1 ...\n",
            " $ A2_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 2 1 1 2 2 2 ...\n",
            " $ A3_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 2 1 1 1 2 2 ...\n",
            " $ A4_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 2 1 2 2 2 1 ...\n",
            " $ A5_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 2 1 2 2 2 1 ...\n",
            " $ A6_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 2 2 2 1 2 2 ...\n",
            " $ A7_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 2 1 2 2 1 1 ...\n",
            " $ A8_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 1 1 2 2 1 1 ...\n",
            " $ A9_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 1 2 2 1 1 2 ...\n",
            " $ A10_Score      : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 1 1 1 2 1 1 ...\n",
            " $ age            : num  15 15 12 14 16 13 16 15 12 12 ...\n",
            " $ gender         : Factor w/ 2 levels \"m\",\"f\": 1 1 2 2 2 2 2 2 1 2 ...\n",
            " $ ethnicity      : Factor w/ 8 levels \"Hispanic\",\"Black\",..: 1 2 NA 3 NA NA NA 4 2 5 ...\n",
            " $ jundice        : Factor w/ 2 levels \"yes\",\"no\": 1 2 2 2 2 2 2 2 1 2 ...\n",
            " $ austim         : Factor w/ 2 levels \"yes\",\"no\": 1 2 2 2 2 2 2 2 1 2 ...\n",
            " $ contry_of_res  : Factor w/ 33 levels \"Austria\",\"AmericanSamoa\",..: 1 1 2 3 4 5 6 7 8 9 ...\n",
            " $ used_app_before: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ result         : num  6 2 2 7 7 3 6 7 6 4 ...\n",
            " $ age_desc       : Factor w/ 2 levels \"12-16 years\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ relation       : Factor w/ 5 levels \"Parent\",\"Relative\",..: 1 2 NA 3 NA NA NA 1 1 1 ...\n",
            " $ Class/ASD      : Factor w/ 2 levels \"NO\",\"YES\": 1 1 1 2 2 1 1 2 1 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 104  21"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 104\n\\item 21\n\\end{enumerate*}\n",
            "text/markdown": "1. 104\n2. 21\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>104</li><li>21</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqvOdAD5DfC",
        "colab_type": "code",
        "outputId": "a38fa406-5140-475d-d9e9-d5bcb2ac34b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Adult Set\n",
        "# Set url link for the location of the dataset\n",
        "      AdultURL <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00426/Autism-Adult-Data%20Plus%20Description%20File.zip\"\n",
        "      \n",
        "      # Download the .zip file and unzip contents\n",
        "      download.file(AdultURL, dest = \"Adult.zip\", mode = \"wb\") \n",
        "      unzip(\"Adult.zip\", exdir = \"Adult\")\n",
        "      \n",
        "      # Assess the files contained in the .zip file and then import each dataset\n",
        "      list.files(\"Adult\")\n",
        "      Autism_Adult_Data <- readARFF(\"Adult/Autism-Adult-Data.arff\")\n",
        "      \n",
        "      #Basic Descriptive Info\n",
        "      Autism_Adult_Data[1:5, 1:10]\n",
        "      str(Autism_Adult_Data)\n",
        "      dim(Autism_Adult_Data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Autism-Adult-Data.arff\"                      \n",
              "[2] \"Autism-Screening-Adult-Data Description.docx\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'Autism-Adult-Data.arff'\n\\item 'Autism-Screening-Adult-Data Description.docx'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'Autism-Adult-Data.arff'\n2. 'Autism-Screening-Adult-Data Description.docx'\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Autism-Adult-Data.arff'</li><li>'Autism-Screening-Adult-Data Description.docx'</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse with reader=readr : Adult/Autism-Adult-Data.arff\n",
            "\n",
            "header: 0.035000; preproc: 0.000000; data: 0.004000; postproc: 0.003000; total: 0.042000\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n",
              "1 1        1        1        1        0        0        1        1       \n",
              "2 1        1        0        1        0        0        0        1       \n",
              "3 1        1        0        1        1        0        1        1       \n",
              "4 1        1        0        1        0        0        1        1       \n",
              "5 1        0        0        0        0        0        0        1       \n",
              "  A9_Score A10_Score\n",
              "1 0        0        \n",
              "2 0        1        \n",
              "3 1        1        \n",
              "4 0        1        \n",
              "5 0        0        "
            ],
            "text/latex": "A data.frame: 5 × 10\n\\begin{tabular}{r|llllllllll}\n  & A1\\_Score & A2\\_Score & A3\\_Score & A4\\_Score & A5\\_Score & A6\\_Score & A7\\_Score & A8\\_Score & A9\\_Score & A10\\_Score\\\\\n  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n\\hline\n\t1 & 1 & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0\\\\\n\t2 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 1\\\\\n\t3 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 1\\\\\n\t4 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1\\\\\n\t5 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 5 × 10\n\n| <!--/--> | A1_Score &lt;fct&gt; | A2_Score &lt;fct&gt; | A3_Score &lt;fct&gt; | A4_Score &lt;fct&gt; | A5_Score &lt;fct&gt; | A6_Score &lt;fct&gt; | A7_Score &lt;fct&gt; | A8_Score &lt;fct&gt; | A9_Score &lt;fct&gt; | A10_Score &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 1 | 1 | 1 | 1 | 0 | 0 | 1 | 1 | 0 | 0 |\n| 2 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 1 |\n| 3 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 | 1 |\n| 4 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 1 |\n| 5 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 |\n\n",
            "text/html": [
              "<table>\n",
              "<caption>A data.frame: 5 × 10</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>A1_Score</th><th scope=col>A2_Score</th><th scope=col>A3_Score</th><th scope=col>A4_Score</th><th scope=col>A5_Score</th><th scope=col>A6_Score</th><th scope=col>A7_Score</th><th scope=col>A8_Score</th><th scope=col>A9_Score</th><th scope=col>A10_Score</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "'data.frame':\t704 obs. of  21 variables:\n",
            " $ A1_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 1 2 2 2 ...\n",
            " $ A2_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 1 2 2 2 2 2 ...\n",
            " $ A3_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 2 1 2 1 2 ...\n",
            " $ A4_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 1 2 1 2 1 2 ...\n",
            " $ A5_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 2 1 1 2 1 ...\n",
            " $ A6_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 2 ...\n",
            " $ A7_Score       : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 2 1 1 1 2 ...\n",
            " $ A8_Score       : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 1 2 2 ...\n",
            " $ A9_Score       : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 2 1 2 2 2 ...\n",
            " $ A10_Score      : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 2 1 1 2 1 ...\n",
            " $ age            : num  26 24 27 35 40 36 17 64 29 17 ...\n",
            " $ gender         : Factor w/ 2 levels \"f\",\"m\": 1 2 2 1 1 2 1 2 2 2 ...\n",
            " $ ethnicity      : Factor w/ 11 levels \"White-European\",..: 1 2 2 1 NA 3 4 1 1 5 ...\n",
            " $ jundice        : Factor w/ 2 levels \"no\",\"yes\": 1 1 2 1 1 2 1 1 1 2 ...\n",
            " $ austim         : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 2 1 1 1 1 1 2 ...\n",
            " $ contry_of_res  : Factor w/ 67 levels \"United States\",..: 1 2 3 1 4 1 1 5 1 6 ...\n",
            " $ used_app_before: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ result         : num  6 5 8 6 2 9 2 5 6 8 ...\n",
            " $ age_desc       : Factor w/ 1 level \"18 and more\": 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ relation       : Factor w/ 5 levels \"Self\",\"Parent\",..: 1 1 2 1 NA 1 1 2 1 3 ...\n",
            " $ Class/ASD      : Factor w/ 2 levels \"NO\",\"YES\": 1 1 2 1 1 2 1 1 1 2 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 704  21"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 704\n\\item 21\n\\end{enumerate*}\n",
            "text/markdown": "1. 704\n2. 21\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>704</li><li>21</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MWKFR0QxdAo",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation\n",
        "There was some heavy amount of preparation that needed to be performed before I could perform any analysis. Because each of the three datasets were small (child, adolescent and adult) my first step was to merge the three data sets into one larger set. There were several NA values that existed in the age column as well as in some of the factor columns (for example ethnicity). For the age NAs, I used the avg age in each of the primary sets (child adolescent, adult) to replace the NA value before merging into one set. For factor columns I created an “Unknown Value”. Several columns also needed to be recategorized to numeric value in order to be able to use them in the various algorithms. \n",
        "Once I had one dataset, I did some additional cleaning of the data. The age column was eliminated since we already had a categorical “age description” column. Since research shows that ASD is not specific to country or ethnicity, I decided to remove those columns as well. Country of origin specifically had 89 different discrete values for this column, so this made the data easier to work with. The remaining values were converted into discrete values, I did this by creating separate variables for each columns option and using 1 and 0 to indicate Yes and No. Had I kept the countries and ethnicities; this would have resulted in over 100 additional variables. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEg1Q9PZRJE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sets for editing\n",
        "AutChild <- Autism_Child_Data\n",
        "AutTeen <- Autism_Adolescent_Data\n",
        "AutAdult <- Autism_Adult_Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1kc1ptIRloW",
        "colab_type": "code",
        "outputId": "cbe7aad8-34f5-414d-f803-ecc6be20b58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#----- Reorganizing Data -----#\n",
        "\n",
        "#I will reoganize my set columns to match the attribute information document provided\n",
        "AutChild <- AutChild[,c(21,11:15,20,16,17,19,1:10,18)]\n",
        "AutTeen <- AutTeen[,c(21,11:15,20,16,17,19,1:10,18)]\n",
        "AutAdult <- AutAdult[,c(21,11:15,20,16,17,19,1:10,18)]\n",
        "\n",
        "#Cleansing errors\n",
        "  #AutAdult\n",
        "  AutAdult$ethnicity <- as.character(AutAdult$ethnicity)\n",
        "  AutAdult$ethnicity[is.na(AutAdult$ethnicity)] <- \"Unknown\"\n",
        "  AutAdult$ethnicity <- as.factor(AutAdult$ethnicity)\n",
        "  AutAdult$relation <- as.character(AutAdult$relation)\n",
        "  AutAdult$relation[is.na(AutAdult$relation)] <- \"Unknown\"\n",
        "  AutAdult$relation <- as.factor(AutAdult$relation)\n",
        "  \n",
        "  #AutChild\n",
        "  AutChild$ethnicity <- as.character(AutChild$ethnicity)\n",
        "  AutChild$ethnicity[is.na(AutChild$ethnicity)] <- \"Unknown\"\n",
        "  AutChild$ethnicity <- as.factor(AutChild$ethnicity)\n",
        "  AutChild$relation <- as.character(AutChild$relation)\n",
        "  AutChild$relation[is.na(AutChild$relation)] <- \"Unknown\"\n",
        "  AutChild$relation <- as.factor(AutChild$relation)\n",
        "  AutChild$relation <- gsub(\"self\", \"Self\", AutChild$relation)\n",
        "\n",
        "  #AutTeen\n",
        "  AutTeen$ethnicity <- as.character(AutTeen$ethnicity)\n",
        "  AutTeen$ethnicity[is.na(AutTeen$ethnicity)] <- \"Unknown\"\n",
        "  AutTeen$ethnicity <- as.factor(AutTeen$ethnicity)\n",
        "  AutTeen$relation <- as.character(AutTeen$relation)\n",
        "  AutTeen$relation[is.na(AutTeen$relation)] <- \"Unknown\"\n",
        "  AutTeen$relation <- as.factor(AutTeen$relation)\n",
        "  AutTeen$age_desc <- as.factor(\"12-17 years\")\n",
        "  \n",
        "  #Replace NAs in age column with mean value\n",
        "  AutAdult$age[is.na(AutAdult$age)] <- mean(AutAdult$age, na.rm=TRUE)\n",
        "  AutChild$age[is.na(AutChild$age)] <- mean(AutChild$age, na.rm=TRUE)\n",
        "  AutTeen$age[is.na(AutTeen$age)] <- mean(AutTeen$age, na.rm=TRUE)\n",
        "\n",
        "  #change col classification\n",
        "  cols = c(11:21);    \n",
        "  AutAdult[,cols] = apply(AutAdult[,cols], 2, function(x) as.numeric(as.character(x)));\n",
        "  AutChild[,cols] = apply(AutChild[,cols], 2, function(x) as.numeric(as.character(x)));\n",
        "  AutTeen[,cols] = apply(AutTeen[,cols], 2, function(x) as.numeric(as.character(x)));\n",
        "\n",
        "  #combining the three sets into one total set\n",
        "  AutTotal <- rbind(AutChild,AutTeen,AutAdult)\n",
        "  colnames(AutTotal)[1] <- \"ClassASD\"\n",
        "  colnames(AutTotal)[6] <- \"AutismInFamily\"\n",
        "  colnames(AutTotal)[8] <- \"country\"\n",
        "  colnames(AutTotal)[9] <- \"used_app\"\n",
        "  summary(AutTotal)\n",
        "  str(AutTotal)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " ClassASD       age         gender            ethnicity   jundice  \n",
              " NO :707   Min.   :  4.00   m:625   White-European :381   no :935  \n",
              " YES:393   1st Qu.: 11.00   f:475   Asian          :185   yes:165  \n",
              "           Median : 21.00           Unknown        :144            \n",
              "           Mean   : 22.03           Middle Eastern :128            \n",
              "           3rd Qu.: 30.00           Black          : 65            \n",
              "           Max.   :383.00           South Asian    : 60            \n",
              "                                    (Other)        :137            \n",
              " AutismInFamily   relation                         country    used_app  \n",
              " no :946        Length:1100        United States       :167   no :1073  \n",
              " yes:154        Class :character   United Kingdom      :155   yes:  27  \n",
              "                Mode  :character   India               :130             \n",
              "                                   New Zealand         : 95             \n",
              "                                   United Arab Emirates: 90             \n",
              "                                   Jordan              : 68             \n",
              "                                   (Other)             :395             \n",
              "        age_desc      A1_Score         A2_Score         A3_Score     \n",
              " 4-11 years :292   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n",
              " 12-17 years:104   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n",
              " 18 and more:704   Median :1.0000   Median :0.0000   Median :1.0000  \n",
              "                   Mean   :0.6991   Mean   :0.4827   Mean   :0.5518  \n",
              "                   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
              "                   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n",
              "                                                                     \n",
              "    A4_Score       A5_Score         A6_Score         A7_Score     \n",
              " Min.   :0.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n",
              " 1st Qu.:0.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n",
              " Median :1.00   Median :1.0000   Median :0.0000   Median :0.0000  \n",
              " Mean   :0.53   Mean   :0.5873   Mean   :0.4436   Mean   :0.4773  \n",
              " 3rd Qu.:1.00   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
              " Max.   :1.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n",
              "                                                                  \n",
              "    A8_Score         A9_Score        A10_Score          result      \n",
              " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 0.000  \n",
              " 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 3.000  \n",
              " Median :1.0000   Median :0.0000   Median :1.0000   Median : 5.000  \n",
              " Mean   :0.6055   Mean   :0.4127   Mean   :0.6218   Mean   : 5.412  \n",
              " 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 7.250  \n",
              " Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :10.000  \n",
              "                                                                    "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "'data.frame':\t1100 obs. of  21 variables:\n",
            " $ ClassASD      : Factor w/ 2 levels \"NO\",\"YES\": 1 1 1 1 2 1 2 2 2 1 ...\n",
            " $ age           : num  6 6 6 5 5 4 5 5 11 11 ...\n",
            " $ gender        : Factor w/ 2 levels \"m\",\"f\": 1 1 1 2 1 1 1 2 2 2 ...\n",
            " $ ethnicity     : Factor w/ 12 levels \"Asian\",\"Black\",..: 6 5 10 10 6 10 11 5 5 10 ...\n",
            " $ jundice       : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 2 2 1 1 1 1 1 ...\n",
            " $ AutismInFamily: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 2 1 1 1 2 ...\n",
            " $ relation      : chr  \"Parent\" \"Parent\" \"Unknown\" \"Unknown\" ...\n",
            " $ country       : Factor w/ 89 levels \"Jordan\",\"United States\",..: 1 1 1 1 2 3 4 5 5 6 ...\n",
            " $ used_app      : Factor w/ 2 levels \"no\",\"yes\": 1 1 2 1 1 1 1 1 1 1 ...\n",
            " $ age_desc      : Factor w/ 3 levels \"4-11 years\",\"12-17 years\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ A1_Score      : num  1 1 1 0 1 0 1 1 1 0 ...\n",
            " $ A2_Score      : num  1 1 1 1 1 0 0 1 1 0 ...\n",
            " $ A3_Score      : num  0 0 0 0 1 1 1 1 1 1 ...\n",
            " $ A4_Score      : num  0 0 0 0 1 0 1 1 1 1 ...\n",
            " $ A5_Score      : num  1 1 0 1 1 1 1 1 1 1 ...\n",
            " $ A6_Score      : num  1 1 1 1 1 1 1 1 1 0 ...\n",
            " $ A7_Score      : num  0 0 1 0 1 0 0 1 1 1 ...\n",
            " $ A8_Score      : num  1 1 1 0 1 1 1 1 0 1 ...\n",
            " $ A9_Score      : num  0 0 0 0 1 0 0 0 0 0 ...\n",
            " $ A10_Score     : num  0 0 0 1 1 1 1 0 0 0 ...\n",
            " $ result        : num  5 5 5 4 10 5 7 8 7 5 ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohXVdTiIRoc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----- Look At ethnicity-----# \n",
        "  List <- NA\n",
        "  List <- sqldf(\"select \n",
        "                          ethnicity\n",
        "                          from AutTotal\n",
        "                          group by ethnicity\")\n",
        "  # I ran List here and observed 12 ethnicities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IIKNDV3RrNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----- Look At countries-----# \n",
        "  List <- NA\n",
        "  List <- sqldf(\"select \n",
        "                          country\n",
        "                          from AutTotal\n",
        "                          group by country\")\n",
        "  # I ran List here and observed 89 countries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zZj9Z-RuXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merge Duplicate Classifications\n",
        "  #AutTotal$gender <- gsub(\"m\", \"Gender-M\", AutTotal$gender)\n",
        "  #AutTotal$gender <- gsub(\"f\", \"Gender-F\", AutTotal$gender)\n",
        "  AutTotal$ethnicity <- gsub(\"Hispanic\", \"Latino\", AutTotal$ethnicity)\n",
        "  AutTotal$ethnicity <- gsub(\"Hispanic\", \"Latino\", AutTotal$ethnicity)\n",
        "  AutTotal$ethnicity <- gsub(\"others\", \"Others\", AutTotal$ethnicity)\n",
        "  AutTotal$ethnicity <- gsub(\"Others\", \"Other-Ethnicity\", AutTotal$ethnicity)\n",
        "  AutTotal$ethnicity <- gsub(\"Unknown\", \"Unknown-Ethnicity\", AutTotal$ethnicity)\n",
        "  AutTotal$jundice <- gsub(\"yes\", \"JundiceY\", AutTotal$jundice)\n",
        "  AutTotal$jundice <- gsub(\"no\", \"JundiceN\", AutTotal$jundice)\n",
        "  AutTotal$AutismInFamily <- gsub(\"yes\", \"FamAutismY\", AutTotal$AutismInFamily)\n",
        "  AutTotal$AutismInFamily <- gsub(\"no\", \"FamAutismN\", AutTotal$AutismInFamily)\n",
        "  AutTotal$relation <- gsub(\"Health care professional\", \"RelationHealthcarePro\", AutTotal$relation)\n",
        "  AutTotal$relation <- gsub(\"Others\", \"RelationOther\", AutTotal$relation)\n",
        "  AutTotal$relation <- gsub(\"Parent\", \"RelationParent\", AutTotal$relation)\n",
        "  AutTotal$relation <- gsub(\"Relative\", \"RelationRelative\", AutTotal$relation)\n",
        "  AutTotal$relation <- gsub(\"Self\", \"RelationSelf\", AutTotal$relation)\n",
        "  AutTotal$relation <- gsub(\"Unknown\", \"RelationUnkown\", AutTotal$relation)\n",
        "  AutTotal$country <- gsub(\"Viet Nam\", \"Vietnam\", AutTotal$country)\n",
        "  AutTotal$used_app <- gsub(\"yes\", \"UsedAppY\", AutTotal$used_app)\n",
        "  AutTotal$used_app <- gsub(\"no\", \"UsedAppN\", AutTotal$used_app)\n",
        "  AutTotal$age_desc <- gsub(\"4-11 years\", \"4to11\", AutTotal$age_desc)\n",
        "  AutTotal$age_desc <- gsub(\"12-17 years\", \"12to17\", AutTotal$age_desc)\n",
        "  AutTotal$age_desc <- gsub(\"18 and more\", \"18Plus\", AutTotal$age_desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBek6oR8RxfY",
        "colab_type": "code",
        "outputId": "b9b50de6-858f-45c4-8d2d-caa5b4b7f963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#New Continent Column created\n",
        "  AutTotal$continent <- countrycode(sourcevar = AutTotal[, \"country\"], origin = \"country.name\", destination = \"continent\")\n",
        "  AutTotal[15, 22] <- \"Europe\"\n",
        "  AutTotal[196, 22] <- \"Americas\"\n",
        "  AutTotal <- AutTotal[,c(1,3,5:7,9:21)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in countrycode(sourcevar = AutTotal[, \"country\"], origin = \"country.name\", :\n",
            "“Some values were not matched unambiguously: Europe, U.S. Outlying Islands\n",
            "”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uykiW9kFdp2b",
        "colab_type": "text"
      },
      "source": [
        "## Questionaire Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdyE-o5he0d7",
        "colab_type": "text"
      },
      "source": [
        "### Create Test and Training Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1X_dmp6fMQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----- Creating Training and Test Sets FOR ONLY Questionaire-----#\n",
        "          #Model shows 100% accuracy in decision tree.\n",
        "          #Predicting factor is a score >6 (results)\n",
        "          Total1 <- AutTotal[,c(1, 8:18)] \n",
        "          #create sets using caret library\n",
        "          inTraining <- createDataPartition(Total1$ClassASD, times = 1, p = .66, list = FALSE)\n",
        "          trainAut <- Total1[ inTraining,]\n",
        "          trainAut$ClassASD <- droplevels( trainAut)$ClassASD\n",
        "          testAut  <- Total1[-inTraining,]\n",
        "          testAut$ClassASD <- droplevels(testAut)$ClassASD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNNeLoubfBVL",
        "colab_type": "text"
      },
      "source": [
        "### Build Model using c50 Algorithmn (c50 library)\n",
        "I created a Decision Tree using the c50 library’s C5.0 algorithm. I first attempted to create a decision tree based on just the survey and final score. My intention was to see if there were any patterns with the answers, however I was surprised with the results. The resulting decision tree was completely based on the result of the survey, <=6 was no expected diagnosis of autism and >6 was expecting a Yes. Upon using the test data on the model, the model accurately predicted the outcome diagnosis 100% of the time.  This raised a red flag as we should never expect 100% accuracy. All other subsequent classification algorithms also produced a 100% Accuracy in prediction, this caused me to want to NOT look at the questionnaire responses and instead look at all the other variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajLry-gDR0Xx",
        "colab_type": "code",
        "outputId": "e456fc70-8202-46cb-dd02-0cef22ad8e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "          #building Model using c50 Algorithim (c50 library)\n",
        "          dt_model <- C5.0(trainAut[-1], trainAut$ClassASD)\n",
        "          dt_model\n",
        "          \n",
        "          summary(dt_model) \n",
        "          \n",
        "          #evaluating performance\n",
        "          pred_model <- predict(dt_model, testAut)\n",
        "          CrossTable(testAut$ClassASD, pred_model, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD)\n",
              "\n",
              "Classification Tree\n",
              "Number of samples: 727 \n",
              "Number of predictors: 11 \n",
              "\n",
              "Tree size: 2 \n",
              "\n",
              "Non-standard options: attempt to group attributes\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD)\n",
              "\n",
              "\n",
              "C5.0 [Release 2.07 GPL Edition]  \tTue Apr 28 16:49:55 2020\n",
              "-------------------------------\n",
              "\n",
              "Class specified by attribute `outcome'\n",
              "\n",
              "Read 727 cases (12 attributes) from undefined.data\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "result <= 6: NO (467)\n",
              "result > 6: YES (260)\n",
              "\n",
              "\n",
              "Evaluation on training data (727 cases):\n",
              "\n",
              "\t    Decision Tree   \n",
              "\t  ----------------  \n",
              "\t  Size      Errors  \n",
              "\n",
              "\t     2    0( 0.0%)   <<\n",
              "\n",
              "\n",
              "\t   (a)   (b)    <-classified as\n",
              "\t  ----  ----\n",
              "\t   467          (a): class NO\n",
              "\t         260    (b): class YES\n",
              "\n",
              "\n",
              "\tAttribute usage:\n",
              "\n",
              "\t100.00%\tresult\n",
              "\n",
              "\n",
              "Time: 0.0 secs\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       240 |         0 |       240 | \n",
            "                 |     0.643 |     0.000 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |         0 |       133 |       133 | \n",
            "                 |     0.000 |     0.357 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       240 |       133 |       373 | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osiou0B-gVCd",
        "colab_type": "text"
      },
      "source": [
        "## All Variables Data (Excluding Questionaire Questions)\n",
        "I decided to create a new set for testing using all the existing variables in the set with the exception of the questionairre responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF1wbEP5nXqo",
        "colab_type": "text"
      },
      "source": [
        "### Create Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emwq5NLfR4Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Expanded  Set for more DM\n",
        "  #help from https://www.r-statistics.com/tag/transpose/\n",
        "  AutExp <- AutTotal\n",
        "                      #----- Step 1: Gender-----# \n",
        "                      List <- NA\n",
        "                      List <- sqldf(\"select \n",
        "                                          Gender\n",
        "                                          from AutExp\n",
        "                                          group by Gender\")\n",
        "                      List1 <- List\n",
        "                      Column <- NA\n",
        "                      Column <- t(List1)\n",
        "                      colnames(Column) <- Column[1,]\n",
        "                      NewDF <- Column\n",
        "                      #Part2\n",
        "                      B <- NA\n",
        "                      B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$gender)))\n",
        "                      B <- as.data.frame (B)\n",
        "                      colnames(B) <- Column\n",
        "                      colnames(B) <- Column[1,]\n",
        "                      \n",
        "                      #Combine\n",
        "              NewAutDF <- cbind(AutExp,B)\n",
        "                     #----- Step 2: Jundice-----# \n",
        "                      List <- NA\n",
        "                      List <- sqldf(\"select \n",
        "                                                          jundice\n",
        "                                                          from AutExp\n",
        "                                                          group by jundice\")\n",
        "                      List1 <- List\n",
        "                      Column <- NA\n",
        "                      Column <- t(List1)\n",
        "                      colnames(Column) <- Column[1,]\n",
        "                      NewDF <- Column\n",
        "                      #Part2\n",
        "                      B <- NA\n",
        "                      B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$jundice)))\n",
        "                      B <- as.data.frame (B)\n",
        "                      colnames(B) <- Column\n",
        "                      colnames(B) <- Column[1,]\n",
        "                      #Combine\n",
        "              NewAutDF <- cbind(NewAutDF,B)\n",
        "                      #----- Step 3: AutismInFamily -----# \n",
        "                      List <- NA\n",
        "                      List <- sqldf(\"select \n",
        "                                                                  AutismInFamily \n",
        "                                                                  from AutExp\n",
        "                                                                  group by AutismInFamily\")\n",
        "                      List1 <- List\n",
        "                      Column <- NA\n",
        "                      Column <- t(List1)\n",
        "                      colnames(Column) <- Column[1,]\n",
        "                      NewDF <- Column\n",
        "                      #Part2\n",
        "                      B <- NA\n",
        "                      B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$AutismInFamily )))\n",
        "                      B <- as.data.frame (B)\n",
        "                      colnames(B) <- Column\n",
        "                      colnames(B) <- Column[1,]\n",
        "                      #Part3\n",
        "              NewAutDF <- cbind(NewAutDF,B)        \n",
        "                      #----- Step 4: Relation -----# \n",
        "                      List <- NA\n",
        "                      List <- sqldf(\"select \n",
        "                                                    relation\n",
        "                                                    from AutExp\n",
        "                                                    group by relation\")\n",
        "                      List1 <- List\n",
        "                      Column <- NA\n",
        "                      Column <- t(List1)\n",
        "                      colnames(Column) <- Column[1,]\n",
        "                      NewDF <- Column\n",
        "                      #Part2\n",
        "                      B <- NA\n",
        "                      B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$relation)))\n",
        "                      B <- as.data.frame (B)\n",
        "                      colnames(B) <- Column\n",
        "                      colnames(B) <- Column[1,]\n",
        "                      #Part3\n",
        "            NewAutDF <- cbind(NewAutDF,B)  \n",
        "                      #----- Step 5: Used App-----# \n",
        "                      List <- NA\n",
        "                      List <- sqldf(\"select \n",
        "                                                                    used_app\n",
        "                                                                    from AutExp\n",
        "                                                                    group by used_app\")\n",
        "                      List1 <- List\n",
        "                      Column <- NA\n",
        "                      Column <- t(List1)\n",
        "                      colnames(Column) <- Column[1,]\n",
        "                      NewDF <- Column\n",
        "                      #Part2\n",
        "                      B <- NA\n",
        "                      B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$used_app)))\n",
        "                      B <- as.data.frame (B)\n",
        "                      colnames(B) <- Column\n",
        "                      colnames(B) <- Column[1,]\n",
        "                      #Part3\n",
        "              NewAutDF <- cbind(NewAutDF,B)  \n",
        "                    #----- Step 5: Age Desc-----# \n",
        "                    List <- NA\n",
        "                    List <- sqldf(\"select \n",
        "                                                                          age_desc\n",
        "                                                                          from AutExp\n",
        "                                                                          group by age_desc\")\n",
        "                    List1 <- List\n",
        "                    Column <- NA\n",
        "                    Column <- t(List1)\n",
        "                    colnames(Column) <- Column[1,]\n",
        "                    NewDF <- Column\n",
        "                    #Part2\n",
        "                    B <- NA\n",
        "                    B <- matrix(NA, nrow = (length(AutExp$ClassASD)), ncol = (length(List$age_desc)))\n",
        "                    B <- as.data.frame (B)\n",
        "                    colnames(B) <- Column\n",
        "                    colnames(B) <- Column[1,]\n",
        "                    #Part3\n",
        "              NewAutDF <- cbind(NewAutDF,B)  \n",
        "  AutExp2 <- NewAutDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVX81v7SAsw",
        "colab_type": "code",
        "outputId": "4a55f9fc-3424-4c96-d962-74e6e052fe9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#2 Fill in Rows for DM\n",
        "  #From https://www.listendata.com/2017/03/if-else-in-r.html\n",
        "  #mydata$x4 = ifelse(mydata$x2>150,1,0)\n",
        "          colnames(AutExp2)\n",
        "\n",
        "          AutExp2[,19] = ifelse((AutExp2[,2])==(colnames(AutExp2[19])),1,0)\n",
        "          AutExp2[,20] = ifelse((AutExp2[,2])==(colnames(AutExp2[20])),1,0)\n",
        "          AutExp2[,21] = ifelse((AutExp2[,3])==(colnames(AutExp2[21])),1,0)\n",
        "          AutExp2[,22] = ifelse((AutExp2[,3])==(colnames(AutExp2[22])),1,0)\n",
        "          AutExp2[,23] = ifelse((AutExp2[,4])==(colnames(AutExp2[23])),1,0)\n",
        "          AutExp2[,24] = ifelse((AutExp2[,4])==(colnames(AutExp2[24])),1,0)\n",
        "          AutExp2[,25] = ifelse((AutExp2[,5])==(colnames(AutExp2[25])),1,0)\n",
        "          AutExp2[,26] = ifelse((AutExp2[,5])==(colnames(AutExp2[26])),1,0)\n",
        "          AutExp2[,27] = ifelse((AutExp2[,5])==(colnames(AutExp2[27])),1,0)\n",
        "          AutExp2[,28] = ifelse((AutExp2[,5])==(colnames(AutExp2[28])),1,0)\n",
        "          AutExp2[,29] = ifelse((AutExp2[,5])==(colnames(AutExp2[29])),1,0)\n",
        "          AutExp2[,30] = ifelse((AutExp2[,5])==(colnames(AutExp2[30])),1,0)\n",
        "          AutExp2[,31] = ifelse((AutExp2[,6])==(colnames(AutExp2[31])),1,0)\n",
        "          AutExp2[,32] = ifelse((AutExp2[,6])==(colnames(AutExp2[32])),1,0)\n",
        "          AutExp2[,33] = ifelse((AutExp2[,7])==(colnames(AutExp2[33])),1,0)\n",
        "          AutExp2[,34] = ifelse((AutExp2[,7])==(colnames(AutExp2[34])),1,0)\n",
        "          AutExp2[,35] = ifelse((AutExp2[,7])==(colnames(AutExp2[35])),1,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " [1] \"ClassASD\"              \"gender\"                \"jundice\"              \n",
              " [4] \"AutismInFamily\"        \"relation\"              \"used_app\"             \n",
              " [7] \"age_desc\"              \"A1_Score\"              \"A2_Score\"             \n",
              "[10] \"A3_Score\"              \"A4_Score\"              \"A5_Score\"             \n",
              "[13] \"A6_Score\"              \"A7_Score\"              \"A8_Score\"             \n",
              "[16] \"A9_Score\"              \"A10_Score\"             \"result\"               \n",
              "[19] \"f\"                     \"m\"                     \"JundiceN\"             \n",
              "[22] \"JundiceY\"              \"FamAutismN\"            \"FamAutismY\"           \n",
              "[25] \"RelationHealthcarePro\" \"RelationOther\"         \"RelationParent\"       \n",
              "[28] \"RelationRelative\"      \"RelationSelf\"          \"RelationUnkown\"       \n",
              "[31] \"UsedAppN\"              \"UsedAppY\"              \"12to17\"               \n",
              "[34] \"18Plus\"                \"4to11\"                "
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'ClassASD'\n\\item 'gender'\n\\item 'jundice'\n\\item 'AutismInFamily'\n\\item 'relation'\n\\item 'used\\_app'\n\\item 'age\\_desc'\n\\item 'A1\\_Score'\n\\item 'A2\\_Score'\n\\item 'A3\\_Score'\n\\item 'A4\\_Score'\n\\item 'A5\\_Score'\n\\item 'A6\\_Score'\n\\item 'A7\\_Score'\n\\item 'A8\\_Score'\n\\item 'A9\\_Score'\n\\item 'A10\\_Score'\n\\item 'result'\n\\item 'f'\n\\item 'm'\n\\item 'JundiceN'\n\\item 'JundiceY'\n\\item 'FamAutismN'\n\\item 'FamAutismY'\n\\item 'RelationHealthcarePro'\n\\item 'RelationOther'\n\\item 'RelationParent'\n\\item 'RelationRelative'\n\\item 'RelationSelf'\n\\item 'RelationUnkown'\n\\item 'UsedAppN'\n\\item 'UsedAppY'\n\\item '12to17'\n\\item '18Plus'\n\\item '4to11'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'ClassASD'\n2. 'gender'\n3. 'jundice'\n4. 'AutismInFamily'\n5. 'relation'\n6. 'used_app'\n7. 'age_desc'\n8. 'A1_Score'\n9. 'A2_Score'\n10. 'A3_Score'\n11. 'A4_Score'\n12. 'A5_Score'\n13. 'A6_Score'\n14. 'A7_Score'\n15. 'A8_Score'\n16. 'A9_Score'\n17. 'A10_Score'\n18. 'result'\n19. 'f'\n20. 'm'\n21. 'JundiceN'\n22. 'JundiceY'\n23. 'FamAutismN'\n24. 'FamAutismY'\n25. 'RelationHealthcarePro'\n26. 'RelationOther'\n27. 'RelationParent'\n28. 'RelationRelative'\n29. 'RelationSelf'\n30. 'RelationUnkown'\n31. 'UsedAppN'\n32. 'UsedAppY'\n33. '12to17'\n34. '18Plus'\n35. '4to11'\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'ClassASD'</li><li>'gender'</li><li>'jundice'</li><li>'AutismInFamily'</li><li>'relation'</li><li>'used_app'</li><li>'age_desc'</li><li>'A1_Score'</li><li>'A2_Score'</li><li>'A3_Score'</li><li>'A4_Score'</li><li>'A5_Score'</li><li>'A6_Score'</li><li>'A7_Score'</li><li>'A8_Score'</li><li>'A9_Score'</li><li>'A10_Score'</li><li>'result'</li><li>'f'</li><li>'m'</li><li>'JundiceN'</li><li>'JundiceY'</li><li>'FamAutismN'</li><li>'FamAutismY'</li><li>'RelationHealthcarePro'</li><li>'RelationOther'</li><li>'RelationParent'</li><li>'RelationRelative'</li><li>'RelationSelf'</li><li>'RelationUnkown'</li><li>'UsedAppN'</li><li>'UsedAppY'</li><li>'12to17'</li><li>'18Plus'</li><li>'4to11'</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0YQopZWnct8",
        "colab_type": "text"
      },
      "source": [
        "### Create Test and Training Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpz7nTGrpEKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----- Creating Traing and Test Sets FOR ALL FACTORS (No quetionaire)-----#\n",
        "        #Total2 <- AutExp2[,c(1, 2, 11:137)] \n",
        "        #Total2 <- AutExp2[,c(1, 2, 22:53)] \n",
        "        Total2 <- AutExp2[,c(1,19:35)]\n",
        "        \n",
        "        #create sets using caret library\n",
        "        inTraining <- createDataPartition(Total2$ClassASD, times = 1, p = .66, list = FALSE)\n",
        "        trainAut <- Total2[ inTraining,]\n",
        "        trainAut$ClassASD <- droplevels( trainAut)$ClassASD\n",
        "        testAut  <- Total2[-inTraining,]\n",
        "        testAut$ClassASD <- droplevels(testAut)$ClassASD\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki-ec1HInwL_",
        "colab_type": "text"
      },
      "source": [
        "### Build Model using c50 Algorithmn (c50 library)\n",
        "I created a new model using all the other variables excluding the survey question and results. The decision tree model created had a probability of being accurate 67% of the time. Upon running my test set. The tree was able to accurately predict the diagnosis 68.63% (237/373) of the time. Below is the resulting decision tree model. As you can see, the attributes that contributed the most to this tree was the age description (12-17 age group) and the relationship of the person who filled out the form. It also seems that the algorithm is having problems correctly predicted “Yes ASD” outcomes. It correctly identified 80.83% of “No ASD” outcome but only correctly predicted 46.61% of “Yes ASD” outcome. Also, when attempting to boost, the number of trials stopped at 2 since the classifier was not accurate. There was no improvement in boosting.  For this data, the decision tree is not a suitable tool for classification. There may possibly be additional variables not accounted for in this data that would aid in better classification via a Decision Tree.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUmWfGAtSD6_",
        "colab_type": "code",
        "outputId": "da789d72-1f3e-4005-efef-67ceaa93221f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "        #building Model using c50 Algorithim (c50 library)\n",
        "        dt_model <- C5.0(trainAut[-1], trainAut$ClassASD)\n",
        "        dt_model #use summary(dt_model) to get the % accuracy and tree\n",
        "        \n",
        "        summary(dt_model) \n",
        "        \n",
        "        #evaluating performance\n",
        "        pred_model <- predict(dt_model, testAut)\n",
        "        CrossTable(testAut$ClassASD, pred_model, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )\n",
        "        \n",
        "        #improving model performance\n",
        "        dt_boost10 <- C5.0(trainAut[-1], trainAut$ClassASD, trials= 10)\n",
        "        dt_boost10 #use summary(dt_boost10) to get the % accuracy and tree\n",
        "        summary(dt_boost10)\n",
        "        \n",
        "        #evaluating boosted performance\n",
        "        pred_model_boost  <- predict(dt_boost10, testAut)\n",
        "        CrossTable(testAut$ClassASD, pred_model_boost, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD)\n",
              "\n",
              "Classification Tree\n",
              "Number of samples: 727 \n",
              "Number of predictors: 17 \n",
              "\n",
              "Tree size: 2 \n",
              "\n",
              "Non-standard options: attempt to group attributes\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD)\n",
              "\n",
              "\n",
              "C5.0 [Release 2.07 GPL Edition]  \tTue Apr 28 16:49:56 2020\n",
              "-------------------------------\n",
              "\n",
              "Class specified by attribute `outcome'\n",
              "\n",
              "Read 727 cases (18 attributes) from undefined.data\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "12to17 <= 0: NO (658/216)\n",
              "12to17 > 0: YES (69/25)\n",
              "\n",
              "\n",
              "Evaluation on training data (727 cases):\n",
              "\n",
              "\t    Decision Tree   \n",
              "\t  ----------------  \n",
              "\t  Size      Errors  \n",
              "\n",
              "\t     2  241(33.1%)   <<\n",
              "\n",
              "\n",
              "\t   (a)   (b)    <-classified as\n",
              "\t  ----  ----\n",
              "\t   442    25    (a): class NO\n",
              "\t   216    44    (b): class YES\n",
              "\n",
              "\n",
              "\tAttribute usage:\n",
              "\n",
              "\t100.00%\t12to17\n",
              "\n",
              "\n",
              "Time: 0.0 secs\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       224 |        16 |       240 | \n",
            "                 |     0.601 |     0.043 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |       114 |        19 |       133 | \n",
            "                 |     0.306 |     0.051 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       338 |        35 |       373 | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD, trials = 10)\n",
              "\n",
              "Classification Tree\n",
              "Number of samples: 727 \n",
              "Number of predictors: 17 \n",
              "\n",
              "Number of boosting iterations: 10 \n",
              "Average tree size: 2.6 \n",
              "\n",
              "Non-standard options: attempt to group attributes\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD, trials = 10)\n",
              "\n",
              "\n",
              "C5.0 [Release 2.07 GPL Edition]  \tTue Apr 28 16:49:56 2020\n",
              "-------------------------------\n",
              "\n",
              "Class specified by attribute `outcome'\n",
              "\n",
              "Read 727 cases (18 attributes) from undefined.data\n",
              "\n",
              "-----  Trial 0:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "12to17 <= 0: NO (658/216)\n",
              "12to17 > 0: YES (69/25)\n",
              "\n",
              "-----  Trial 1:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (99.8/22.6)\n",
              "RelationUnkown <= 0:\n",
              ":...18Plus <= 0: YES (241.2/103.6)\n",
              "    18Plus > 0: NO (386.1/149.2)\n",
              "\n",
              "-----  Trial 2:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (95.4/25.8)\n",
              "RelationUnkown <= 0:\n",
              ":...FamAutismN <= 0: YES (108.8/46.1)\n",
              "    FamAutismN > 0: NO (522.8/232)\n",
              "\n",
              "-----  Trial 3:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (92.6/27.9)\n",
              "RelationUnkown <= 0:\n",
              ":...JundiceN <= 0: YES (98.4/42.8)\n",
              "    JundiceN > 0:\n",
              "    :...f <= 0: NO (299.3/129.8)\n",
              "        f > 0: YES (236.7/109.9)\n",
              "\n",
              "-----  Trial 4:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationParent <= 0: NO (509.8/221.6)\n",
              "RelationParent > 0: YES (217.2/99.8)\n",
              "\n",
              "-----  Trial 5:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (88.4/30.9)\n",
              "RelationUnkown <= 0:\n",
              ":...12to17 <= 0: NO (570/275.7)\n",
              "    12to17 > 0: YES (68.6/29.5)\n",
              "\n",
              "-----  Trial 6:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown <= 0: YES (653.7/315.5)\n",
              "RelationUnkown > 0: NO (55.3)\n",
              "\n",
              "-----  Trial 7:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (52.6)\n",
              "RelationUnkown <= 0:\n",
              ":...JundiceN <= 0: YES (101.1/47)\n",
              "    JundiceN > 0: NO (554.4/267.3)\n",
              "\n",
              "-----  Trial 8:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (49.8)\n",
              "RelationUnkown <= 0:\n",
              ":...18Plus <= 0: YES (291.3/113.5)\n",
              "    18Plus > 0: NO (268.9/61.1)\n",
              "\n",
              "-----  Trial 9:  -----\n",
              "\n",
              "Decision tree:\n",
              " NO (559/173.2)\n",
              "\n",
              "\n",
              "Evaluation on training data (727 cases):\n",
              "\n",
              "Trial\t    Decision Tree   \n",
              "-----\t  ----------------  \n",
              "\t  Size      Errors  \n",
              "\n",
              "   0\t     2  241(33.1%)\n",
              "   1\t     3  246(33.8%)\n",
              "   2\t     3  260(35.8%)\n",
              "   3\t     4  297(40.9%)\n",
              "   4\t     2  260(35.8%)\n",
              "   5\t     3  238(32.7%)\n",
              "   6\t     2  398(54.7%)\n",
              "   7\t     3  260(35.8%)\n",
              "   8\t     3  246(33.8%)\n",
              "   9\t     1  260(35.8%)\n",
              "boost\t        236(32.5%)   <<\n",
              "\n",
              "\n",
              "\t   (a)   (b)    <-classified as\n",
              "\t  ----  ----\n",
              "\t   425    42    (a): class NO\n",
              "\t   194    66    (b): class YES\n",
              "\n",
              "\n",
              "\tAttribute usage:\n",
              "\n",
              "\t100.00%\tRelationParent\n",
              "\t100.00%\tRelationUnkown\n",
              "\t100.00%\t12to17\n",
              "\t 85.56%\tJundiceN\n",
              "\t 85.56%\tFamAutismN\n",
              "\t 85.56%\t18Plus\n",
              "\t 73.45%\tf\n",
              "\n",
              "\n",
              "Time: 0.0 secs\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       219 |        21 |       240 | \n",
            "                 |     0.587 |     0.056 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |       104 |        29 |       133 | \n",
            "                 |     0.279 |     0.078 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       323 |        50 |       373 | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQI7wcnn-R0",
        "colab_type": "text"
      },
      "source": [
        "#### Boost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL5QQOvxoGvc",
        "colab_type": "code",
        "outputId": "c2295e5f-016a-4c7f-cd95-72fc5ada6b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "        #improving model performance\n",
        "        dt_boost10 <- C5.0(trainAut[-1], trainAut$ClassASD, trials= 10)\n",
        "        dt_boost10 #use summary(dt_boost10) to get the % accuracy and tree\n",
        "        summary(dt_boost10)\n",
        "        \n",
        "        #evaluating boosted performance\n",
        "        pred_model_boost  <- predict(dt_boost10, testAut)\n",
        "        CrossTable(testAut$ClassASD, pred_model_boost, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD, trials = 10)\n",
              "\n",
              "Classification Tree\n",
              "Number of samples: 727 \n",
              "Number of predictors: 17 \n",
              "\n",
              "Number of boosting iterations: 10 \n",
              "Average tree size: 2.6 \n",
              "\n",
              "Non-standard options: attempt to group attributes\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "C5.0.default(x = trainAut[-1], y = trainAut$ClassASD, trials = 10)\n",
              "\n",
              "\n",
              "C5.0 [Release 2.07 GPL Edition]  \tTue Apr 28 16:49:56 2020\n",
              "-------------------------------\n",
              "\n",
              "Class specified by attribute `outcome'\n",
              "\n",
              "Read 727 cases (18 attributes) from undefined.data\n",
              "\n",
              "-----  Trial 0:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "12to17 <= 0: NO (658/216)\n",
              "12to17 > 0: YES (69/25)\n",
              "\n",
              "-----  Trial 1:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (99.8/22.6)\n",
              "RelationUnkown <= 0:\n",
              ":...18Plus <= 0: YES (241.2/103.6)\n",
              "    18Plus > 0: NO (386.1/149.2)\n",
              "\n",
              "-----  Trial 2:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (95.4/25.8)\n",
              "RelationUnkown <= 0:\n",
              ":...FamAutismN <= 0: YES (108.8/46.1)\n",
              "    FamAutismN > 0: NO (522.8/232)\n",
              "\n",
              "-----  Trial 3:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (92.6/27.9)\n",
              "RelationUnkown <= 0:\n",
              ":...JundiceN <= 0: YES (98.4/42.8)\n",
              "    JundiceN > 0:\n",
              "    :...f <= 0: NO (299.3/129.8)\n",
              "        f > 0: YES (236.7/109.9)\n",
              "\n",
              "-----  Trial 4:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationParent <= 0: NO (509.8/221.6)\n",
              "RelationParent > 0: YES (217.2/99.8)\n",
              "\n",
              "-----  Trial 5:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (88.4/30.9)\n",
              "RelationUnkown <= 0:\n",
              ":...12to17 <= 0: NO (570/275.7)\n",
              "    12to17 > 0: YES (68.6/29.5)\n",
              "\n",
              "-----  Trial 6:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown <= 0: YES (653.7/315.5)\n",
              "RelationUnkown > 0: NO (55.3)\n",
              "\n",
              "-----  Trial 7:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (52.6)\n",
              "RelationUnkown <= 0:\n",
              ":...JundiceN <= 0: YES (101.1/47)\n",
              "    JundiceN > 0: NO (554.4/267.3)\n",
              "\n",
              "-----  Trial 8:  -----\n",
              "\n",
              "Decision tree:\n",
              "\n",
              "RelationUnkown > 0: NO (49.8)\n",
              "RelationUnkown <= 0:\n",
              ":...18Plus <= 0: YES (291.3/113.5)\n",
              "    18Plus > 0: NO (268.9/61.1)\n",
              "\n",
              "-----  Trial 9:  -----\n",
              "\n",
              "Decision tree:\n",
              " NO (559/173.2)\n",
              "\n",
              "\n",
              "Evaluation on training data (727 cases):\n",
              "\n",
              "Trial\t    Decision Tree   \n",
              "-----\t  ----------------  \n",
              "\t  Size      Errors  \n",
              "\n",
              "   0\t     2  241(33.1%)\n",
              "   1\t     3  246(33.8%)\n",
              "   2\t     3  260(35.8%)\n",
              "   3\t     4  297(40.9%)\n",
              "   4\t     2  260(35.8%)\n",
              "   5\t     3  238(32.7%)\n",
              "   6\t     2  398(54.7%)\n",
              "   7\t     3  260(35.8%)\n",
              "   8\t     3  246(33.8%)\n",
              "   9\t     1  260(35.8%)\n",
              "boost\t        236(32.5%)   <<\n",
              "\n",
              "\n",
              "\t   (a)   (b)    <-classified as\n",
              "\t  ----  ----\n",
              "\t   425    42    (a): class NO\n",
              "\t   194    66    (b): class YES\n",
              "\n",
              "\n",
              "\tAttribute usage:\n",
              "\n",
              "\t100.00%\tRelationParent\n",
              "\t100.00%\tRelationUnkown\n",
              "\t100.00%\t12to17\n",
              "\t 85.56%\tJundiceN\n",
              "\t 85.56%\tFamAutismN\n",
              "\t 85.56%\t18Plus\n",
              "\t 73.45%\tf\n",
              "\n",
              "\n",
              "Time: 0.0 secs\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       219 |        21 |       240 | \n",
            "                 |     0.587 |     0.056 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |       104 |        29 |       133 | \n",
            "                 |     0.279 |     0.078 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       323 |        50 |       373 | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBYInX2Yprt-",
        "colab_type": "text"
      },
      "source": [
        "### Build Naive Bayes Model\n",
        "Next, I applied the Naïve Bayes algorithm via the e1071 package. The Naïve Bayes performed better than the Decision Tree, I ran improved model with a laplace value of 3. The Naïve Bayes model performed significantly better than the decision tree. Since the classifier is not looking for interdependence, it was able to do a better job of classifying the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r44ef1z0p3Ca",
        "colab_type": "code",
        "outputId": "89cd4997-f5af-44dd-8745-2abe40fbd319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#----- Use Na?ve Bayes Model-----# \n",
        "        #build the classifiers\n",
        "        Autclassifier<- naiveBayes(trainAut, trainAut$ClassASD)\n",
        "        Autclassifier\n",
        "        \n",
        "        #evaluate model classfier\n",
        "        Auttestpredicter <- predict(Autclassifier, testAut)\n",
        "      \n",
        "        #compare predictions to true values\n",
        "        CrossTable(testAut$ClassASD, Auttestpredicter, prop.chisq = FALSE, prop.t = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )\n",
        "      \n",
        "        #create confusion matrix\n",
        "        cMatrix <- table(Auttestpredicter, testAut$ClassASD)\n",
        "        plot(cMatrix)\n",
        "        confusionMatrix(cMatrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Naive Bayes Classifier for Discrete Predictors\n",
              "\n",
              "Call:\n",
              "naiveBayes.default(x = trainAut, y = trainAut$ClassASD)\n",
              "\n",
              "A-priori probabilities:\n",
              "trainAut$ClassASD\n",
              "       NO       YES \n",
              "0.6423659 0.3576341 \n",
              "\n",
              "Conditional probabilities:\n",
              "                 ClassASD\n",
              "trainAut$ClassASD NO YES\n",
              "              NO   1   0\n",
              "              YES  0   1\n",
              "\n",
              "                 f\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.4304069 0.4956641\n",
              "              YES 0.4692308 0.5000148\n",
              "\n",
              "                 m\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.5695931 0.4956641\n",
              "              YES 0.5307692 0.5000148\n",
              "\n",
              "                 JundiceN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.8715203 0.3349820\n",
              "              YES 0.8076923 0.3948736\n",
              "\n",
              "                 JundiceY\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.1284797 0.3349820\n",
              "              YES 0.1923077 0.3948736\n",
              "\n",
              "                 FamAutismN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.8822270 0.3226848\n",
              "              YES 0.8038462 0.3978521\n",
              "\n",
              "                 FamAutismY\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.1177730 0.3226848\n",
              "              YES 0.1961538 0.3978521\n",
              "\n",
              "                 RelationHealthcarePro\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.01070664 0.1030278\n",
              "              YES 0.01923077 0.1376000\n",
              "\n",
              "                 RelationOther\n",
              "trainAut$ClassASD        [,1]       [,2]\n",
              "              NO  0.004282655 0.06537174\n",
              "              YES 0.007692308 0.08753632\n",
              "\n",
              "                 RelationParent\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.2141328 0.4106593\n",
              "              YES 0.3846154 0.4874425\n",
              "\n",
              "                 RelationRelative\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.04710921 0.2120996\n",
              "              YES 0.05384615 0.2261492\n",
              "\n",
              "                 RelationSelf\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.5374732 0.4991285\n",
              "              YES 0.4653846 0.4997623\n",
              "\n",
              "                 RelationUnkown\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.18629550 0.3897625\n",
              "              YES 0.06923077 0.2543357\n",
              "\n",
              "                 UsedAppN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.9785867 0.1449128\n",
              "              YES 0.9769231 0.1504374\n",
              "\n",
              "                 UsedAppY\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.02141328 0.1449128\n",
              "              YES 0.02307692 0.1504374\n",
              "\n",
              "                 12to17\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.05353319 0.2253356\n",
              "              YES 0.16923077 0.3756788\n",
              "\n",
              "                 18Plus\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.7194861 0.4497321\n",
              "              YES 0.4807692 0.5005936\n",
              "\n",
              "                 4to11\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.2269807 0.4193292\n",
              "              YES 0.3500000 0.4778895\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|           N / Row Total |\n",
            "|           N / Col Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       228 |        12 |       240 | \n",
            "                 |     0.950 |     0.050 |     0.643 | \n",
            "                 |     0.991 |     0.084 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |         2 |       131 |       133 | \n",
            "                 |     0.015 |     0.985 |     0.357 | \n",
            "                 |     0.009 |     0.916 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       230 |       143 |       373 | \n",
            "                 |     0.617 |     0.383 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "                \n",
              "Auttestpredicter  NO YES\n",
              "             NO  228   2\n",
              "             YES  12 131\n",
              "                                          \n",
              "               Accuracy : 0.9625          \n",
              "                 95% CI : (0.9378, 0.9793)\n",
              "    No Information Rate : 0.6434          \n",
              "    P-Value [Acc > NIR] : < 2e-16         \n",
              "                                          \n",
              "                  Kappa : 0.9196          \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 0.01616         \n",
              "                                          \n",
              "            Sensitivity : 0.9500          \n",
              "            Specificity : 0.9850          \n",
              "         Pos Pred Value : 0.9913          \n",
              "         Neg Pred Value : 0.9161          \n",
              "             Prevalence : 0.6434          \n",
              "         Detection Rate : 0.6113          \n",
              "   Detection Prevalence : 0.6166          \n",
              "      Balanced Accuracy : 0.9675          \n",
              "                                          \n",
              "       'Positive' Class : NO              \n",
              "                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC4lBMVEUAAAABAQECAgIDAwME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\nICRAgJAAAUICBAgJECAkQOD/AUfguWr7GRwOAAAAAElFTkSuQmCC",
            "text/plain": [
              "Plot with title “cMatrix”"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 420,
              "height": 420
            },
            "text/plain": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSYUefAup53A",
        "colab_type": "text"
      },
      "source": [
        "#### Improve Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUI51ezSIgP",
        "colab_type": "code",
        "outputId": "45ea0d23-d75b-49be-a392-104b06267dd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "        \n",
        "        #build improved model\n",
        "        Autclassifier2<- naiveBayes(trainAut, trainAut$ClassASD, laplace = 3)\n",
        "        Autclassifier2\n",
        "        \n",
        "        #evaluate improved model\n",
        "        Auttestpredicter2 <- predict(Autclassifier2, testAut)\n",
        "        \n",
        "        #compare improved predictions to true values\n",
        "        CrossTable(testAut$ClassASD, Auttestpredicter2, prop.chisq = FALSE, prop.t = FALSE, dnn = c('actual diagnosis', 'predicted diagnosis') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Naive Bayes Classifier for Discrete Predictors\n",
              "\n",
              "Call:\n",
              "naiveBayes.default(x = trainAut, y = trainAut$ClassASD, laplace = 3)\n",
              "\n",
              "A-priori probabilities:\n",
              "trainAut$ClassASD\n",
              "       NO       YES \n",
              "0.6423659 0.3576341 \n",
              "\n",
              "Conditional probabilities:\n",
              "                 ClassASD\n",
              "trainAut$ClassASD          NO         YES\n",
              "              NO  0.993657505 0.006342495\n",
              "              YES 0.011278195 0.988721805\n",
              "\n",
              "                 f\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.4304069 0.4956641\n",
              "              YES 0.4692308 0.5000148\n",
              "\n",
              "                 m\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.5695931 0.4956641\n",
              "              YES 0.5307692 0.5000148\n",
              "\n",
              "                 JundiceN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.8715203 0.3349820\n",
              "              YES 0.8076923 0.3948736\n",
              "\n",
              "                 JundiceY\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.1284797 0.3349820\n",
              "              YES 0.1923077 0.3948736\n",
              "\n",
              "                 FamAutismN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.8822270 0.3226848\n",
              "              YES 0.8038462 0.3978521\n",
              "\n",
              "                 FamAutismY\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.1177730 0.3226848\n",
              "              YES 0.1961538 0.3978521\n",
              "\n",
              "                 RelationHealthcarePro\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.01070664 0.1030278\n",
              "              YES 0.01923077 0.1376000\n",
              "\n",
              "                 RelationOther\n",
              "trainAut$ClassASD        [,1]       [,2]\n",
              "              NO  0.004282655 0.06537174\n",
              "              YES 0.007692308 0.08753632\n",
              "\n",
              "                 RelationParent\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.2141328 0.4106593\n",
              "              YES 0.3846154 0.4874425\n",
              "\n",
              "                 RelationRelative\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.04710921 0.2120996\n",
              "              YES 0.05384615 0.2261492\n",
              "\n",
              "                 RelationSelf\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.5374732 0.4991285\n",
              "              YES 0.4653846 0.4997623\n",
              "\n",
              "                 RelationUnkown\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.18629550 0.3897625\n",
              "              YES 0.06923077 0.2543357\n",
              "\n",
              "                 UsedAppN\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.9785867 0.1449128\n",
              "              YES 0.9769231 0.1504374\n",
              "\n",
              "                 UsedAppY\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.02141328 0.1449128\n",
              "              YES 0.02307692 0.1504374\n",
              "\n",
              "                 12to17\n",
              "trainAut$ClassASD       [,1]      [,2]\n",
              "              NO  0.05353319 0.2253356\n",
              "              YES 0.16923077 0.3756788\n",
              "\n",
              "                 18Plus\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.7194861 0.4497321\n",
              "              YES 0.4807692 0.5005936\n",
              "\n",
              "                 4to11\n",
              "trainAut$ClassASD      [,1]      [,2]\n",
              "              NO  0.2269807 0.4193292\n",
              "              YES 0.3500000 0.4778895\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|           N / Row Total |\n",
            "|           N / Col Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "                 | predicted diagnosis \n",
            "actual diagnosis |        NO |       YES | Row Total | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "              NO |       223 |        17 |       240 | \n",
            "                 |     0.929 |     0.071 |     0.643 | \n",
            "                 |     0.978 |     0.117 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "             YES |         5 |       128 |       133 | \n",
            "                 |     0.038 |     0.962 |     0.357 | \n",
            "                 |     0.022 |     0.883 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "    Column Total |       228 |       145 |       373 | \n",
            "                 |     0.611 |     0.389 |           | \n",
            "-----------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp7zC8yyq0MP",
        "colab_type": "text"
      },
      "source": [
        "### Build k-NN Model\n",
        "Next, I used the class package to apply the K-NN classification algorithm. The original unscaled version of the model I created only produced a 62.4% accuracy when tested. Like the Decision Tree Model, it has an issue with over reporting the “No-ASD” classification. I attempted to improve the model by rescaling using z-score standardization. This improved the accuracy slightly to 68.63%. The issue is still with the misclassification of the “Yes-ASD” outcome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4sS-GYxrIwB",
        "colab_type": "code",
        "outputId": "3e3da107-048e-4318-f55d-872564e63f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "#----- Use k-NN Model-----# \n",
        "        #model training\n",
        "        trainAutlabel <- trainAut[,1]\n",
        "        testAutlabel <- testAut [,1]\n",
        "        knnAutSpread <- knn(train=trainAut[,-1], testAut [,-1], cl=trainAutlabel, k=7)\n",
        "        summary(knnAutSpread)\n",
        "        CrossTable(x=testAutlabel, y=knnAutSpread, prop.chisq = FALSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " NO YES \n",
              "305  68 "
            ],
            "text/latex": "\\begin{description*}\n\\item[NO] 305\n\\item[YES] 68\n\\end{description*}\n",
            "text/markdown": "NO\n:   305YES\n:   68\n\n",
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>NO</dt><dd>305</dd><dt>YES</dt><dd>68</dd></dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|           N / Row Total |\n",
            "|           N / Col Total |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "             | knnAutSpread \n",
            "testAutlabel |        NO |       YES | Row Total | \n",
            "-------------|-----------|-----------|-----------|\n",
            "          NO |       206 |        34 |       240 | \n",
            "             |     0.858 |     0.142 |     0.643 | \n",
            "             |     0.675 |     0.500 |           | \n",
            "             |     0.552 |     0.091 |           | \n",
            "-------------|-----------|-----------|-----------|\n",
            "         YES |        99 |        34 |       133 | \n",
            "             |     0.744 |     0.256 |     0.357 | \n",
            "             |     0.325 |     0.500 |           | \n",
            "             |     0.265 |     0.091 |           | \n",
            "-------------|-----------|-----------|-----------|\n",
            "Column Total |       305 |        68 |       373 | \n",
            "             |     0.818 |     0.182 |           | \n",
            "-------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tclEj4hXrHj4",
        "colab_type": "text"
      },
      "source": [
        "#### Improve Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ff4dodwSM_F",
        "colab_type": "code",
        "outputId": "7cfdc575-7b1b-42c9-8822-4759c6dea306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "      #improved performance using z-score standardization\n",
        "        #new model training\n",
        "        Total2z <- as.data.frame(scale(Total2[,-1]))\n",
        "        Total2z_train <- Total2z[1:733,]\n",
        "        Total2z_test <- Total2z[734:1100,]\n",
        "        Total2z_train_label <- Total2[1:733,1]\n",
        "        Total2z_test_label <- Total2[734:1100,1]\n",
        "        \n",
        "        #new performance\n",
        "        knnAutPrediction <- knn(train=Total2z_train, Total2z_test, cl=Total2z_train_label, k=11)\n",
        "        summary(knnAutPrediction)\n",
        "        CrossTable(x=Total2z_test_label, y=knnAutPrediction, prop.chisq = FALSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " NO YES \n",
              "332  35 "
            ],
            "text/latex": "\\begin{description*}\n\\item[NO] 332\n\\item[YES] 35\n\\end{description*}\n",
            "text/markdown": "NO\n:   332YES\n:   35\n\n",
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>NO</dt><dd>332</dd><dt>YES</dt><dd>35</dd></dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|           N / Row Total |\n",
            "|           N / Col Total |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  367 \n",
            "\n",
            " \n",
            "                   | knnAutPrediction \n",
            "Total2z_test_label |        NO |       YES | Row Total | \n",
            "-------------------|-----------|-----------|-----------|\n",
            "                NO |       247 |        26 |       273 | \n",
            "                   |     0.905 |     0.095 |     0.744 | \n",
            "                   |     0.744 |     0.743 |           | \n",
            "                   |     0.673 |     0.071 |           | \n",
            "-------------------|-----------|-----------|-----------|\n",
            "               YES |        85 |         9 |        94 | \n",
            "                   |     0.904 |     0.096 |     0.256 | \n",
            "                   |     0.256 |     0.257 |           | \n",
            "                   |     0.232 |     0.025 |           | \n",
            "-------------------|-----------|-----------|-----------|\n",
            "      Column Total |       332 |        35 |       367 | \n",
            "                   |     0.905 |     0.095 |           | \n",
            "-------------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoYhmHXJsBlL",
        "colab_type": "text"
      },
      "source": [
        "### Build SVM Model\n",
        "Lastly, I attempted classify using the kernlab package to use the SVM algorithm. When running the model using the vanilladot (basic linear) kernel, the model had a 65.68% accuracy in predicting the outcome. I attempted to improve the model’s performance by using the rbfdot (Radial basis/Gaussian), however this resulted in less accuracy (64.87%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sideywOxsFRi",
        "colab_type": "code",
        "outputId": "5dccb85e-264a-4275-af04-3cc0e0153e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "#----- Use SVM Model-----#      \n",
        "        #build the model classifier\n",
        "        ksvmmodelclassifier <- ksvm(ClassASD ~ ., data=trainAut, kernel =\"vanilladot\")\n",
        "        ksvmmodelclassifier\n",
        "        \n",
        "        #evaluate performance\n",
        "        ksmvmodelpredictions  <- predict(ksvmmodelclassifier, testAut)\n",
        "        CrossTable(testAut$ClassASD, ksmvmodelpredictions, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual number', 'predicted number') )\n",
        "        #model predicted 236 / 373 (63.27%)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Setting default kernel parameters  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Support Vector Machine object of class \"ksvm\" \n",
              "\n",
              "SV type: C-svc  (classification) \n",
              " parameter : cost C = 1 \n",
              "\n",
              "Linear (vanilla) kernel function. \n",
              "\n",
              "Number of Support Vectors : 505 \n",
              "\n",
              "Objective Function Value : -482.1433 \n",
              "Training error : 0.331499 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "              | predicted number \n",
            "actual number |        NO |       YES | Row Total | \n",
            "--------------|-----------|-----------|-----------|\n",
            "           NO |       224 |        16 |       240 | \n",
            "              |     0.601 |     0.043 |           | \n",
            "--------------|-----------|-----------|-----------|\n",
            "          YES |       114 |        19 |       133 | \n",
            "              |     0.306 |     0.051 |           | \n",
            "--------------|-----------|-----------|-----------|\n",
            " Column Total |       338 |        35 |       373 | \n",
            "--------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7wP9if6sHpe",
        "colab_type": "text"
      },
      "source": [
        "#### Improve Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_wA-5HfSRUd",
        "colab_type": "code",
        "outputId": "ab818453-8f7e-4176-a2c0-e671881976d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "        #improved performance\n",
        "        ksvmmodelclassifierrbf <- ksvm(ClassASD ~ ., data=trainAut, kernel =\"rbfdot\")\n",
        "        ksvmmodelclassifierrbf\n",
        "        ksmvmodelpredictionsrbf  <- predict(ksvmmodelclassifierrbf, testAut)\n",
        "        CrossTable(testAut$ClassASD, ksmvmodelpredictionsrbf, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual number', 'predicted number') )\n",
        "        #model predicted 247/ 373 (66.21%)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Support Vector Machine object of class \"ksvm\" \n",
              "\n",
              "SV type: C-svc  (classification) \n",
              " parameter : cost C = 1 \n",
              "\n",
              "Gaussian Radial Basis kernel function. \n",
              " Hyperparameter : sigma =  0.0490338963559971 \n",
              "\n",
              "Number of Support Vectors : 506 \n",
              "\n",
              "Objective Function Value : -466.0458 \n",
              "Training error : 0.290234 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            "   Cell Contents\n",
            "|-------------------------|\n",
            "|                       N |\n",
            "|         N / Table Total |\n",
            "|-------------------------|\n",
            "\n",
            " \n",
            "Total Observations in Table:  373 \n",
            "\n",
            " \n",
            "              | predicted number \n",
            "actual number |        NO |       YES | Row Total | \n",
            "--------------|-----------|-----------|-----------|\n",
            "           NO |       210 |        30 |       240 | \n",
            "              |     0.563 |     0.080 |           | \n",
            "--------------|-----------|-----------|-----------|\n",
            "          YES |        97 |        36 |       133 | \n",
            "              |     0.260 |     0.097 |           | \n",
            "--------------|-----------|-----------|-----------|\n",
            " Column Total |       307 |        66 |       373 | \n",
            "--------------|-----------|-----------|-----------|\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZVfP8cpxXHr",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "I found the results very odd. It seems that when taking into account the AQ-10 responses and score, all the algorithms were able to classify. ASD outcome 100% of the time. When looking at all the behavioral factors, there was a steep decline in the accuracy, with the exception of Naïve Bayes.\n",
        "\n",
        "![alt text](https://github.com/frnunez/MS-Portfolio-Syracuse-University/raw/master/IST%20707%20-%20Data%20Analytics%20-%20Classification%20of%20ASD%20Screening%20Data/asdresults.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lzeq6oNyiGZ",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "So how is this possible? Is the AQ-10 really that good of a predicter? Are there more factors at play than the variables in this data set? I looked up a few research articles, to see what information was available regarding the AQ tool.  A study in the Journal of Autism and Development Disorders concluded that there is little difference in results of the AQ-10 and AQ-50 and the AQ-10 can be a potentially useful screening tool (Booth, etal 2013). A later study in Psychological Medicine concluded that not were AQ scores not a significant predictor of diagnosis for ASD, but that the 64% of those who scored below the cut off and had a “No-ASD” outcome were actually false negatives who were later in fact diagnosed with ASD (Ashwood, etal, 2016). This led me to look at the provided data sets more. Upon further inspection, I noticed that the data was bias. All individuals with an AQ score of >=6 later received a No diagnosis. There were no signs of any false positives or negatives. This explains why there was a 100% accurate prediction when using using the AQ-10 responses and score. \n",
        "With regards to the other factors, I believe there are two issues at play. First there needs to be more data as there isn’t a variance in results. Second, since ASD is still being studied I believe that there are several other variables at play which aren’t included in this data set, and may prove as better predictors to classify ASD. I believe more data should be collected, including expanding the variables being recorded.\n"
      ]
    }
  ]
}